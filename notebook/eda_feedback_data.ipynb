{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6ac6e6",
   "metadata": {},
   "source": [
    "# Google Sheet Survey ETL Analysis: Pipeline Fundamentals\n",
    "\n",
    "## Dylan K. Picart\n",
    "\n",
    "This notebook walks through the **key logic** of the 10 main scripts in the ETL workflow, from extraction to Excel output.\n",
    "Each section is a self-contained example of how the script works, and can be expanded for testing or demonstration.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e05c78",
   "metadata": {},
   "source": [
    "## Extract\n",
    "\n",
    "### 1. `extract/scrape_drive_links.py` (Google Drive Download)\n",
    "\n",
    "> **Purpose:**\n",
    "> Authenticates with Google Drive/Sheets API and scrapes all survey spreadsheets and tabs from a specified root folder.     \n",
    "> Organizes found sheets/tabs by year and (anonymized) category (e.g., \"Group A\" / \"Group B\").      \n",
    "> Saves a `links.yaml` config file mapping all available files/tabs for use by later scripts.   \n",
    "> **Input:** Google Drive folder ID, Google API credentials     \n",
    "> **Output:** YAML file (`data/configs/links.yaml`) with all survey sheet links/tabs, categorized for downstream ETL.\n",
    "\n",
    "```python\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "creds = Credentials.from_service_account_file('secrets/service_account.json', scopes=[\n",
    "    'https://www.googleapis.com/auth/drive.readonly'\n",
    "])\n",
    "gc = gspread.authorize(creds)\n",
    "\n",
    "# Download all sheets from a folder (Google Sheets API example)\n",
    "folder_id = \"<your-folder-id>\"\n",
    "from googleapiclient.discovery import build\n",
    "service = build('drive', 'v3', credentials=creds)\n",
    "files = service.files().list(q=f\"'{folder_id}' in parents\", fields=\"files(id, name)\").execute()['files']\n",
    "\n",
    "for file in files:\n",
    "    # Export each Google Sheet as CSV\n",
    "    request = service.files().export_media(fileId=file['id'], mimeType='text/csv')\n",
    "    with open(f\"raw/{file['name']}.csv\", \"wb\") as f:\n",
    "        f.write(request.execute())\n",
    "```\n",
    "\n",
    "### 2. `extract/load_feedback_data.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Loads and merges survey data from cloud links (YAML), cleans headers/whitespace, merges across schools/tabs, and writes a raw, cleaned CSV for each group and year.   \n",
    "> **Input:** `links.yaml`     \n",
    "> **Output:** Cleaned CSV files (e.g., `data/raw/group_a_2021.csv`).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"raw/2021_GROUP_A.csv\")\n",
    "df.columns = [col.strip().replace(\"\\xa0\", \" \") for col in df.columns]\n",
    "df = df.dropna(how='all')\n",
    "df.to_csv(\"processed/group_a/feedback_2021.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `extract/raw_audit.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Extracts all question columns from the raw CSVs, catalogs unique questions, and exports a per-group audit CSV for mapping (e.g., `audit_group_a.csv`).       \n",
    "> **Input:** Raw cleaned CSV    \n",
    "> **Output:** Audit CSV with all question columns.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed/group_a/feedback_2021.csv\")\n",
    "questions = pd.DataFrame({\"Raw Question\": df.columns})\n",
    "questions.to_csv(\"audit_group_a.csv\", index=False)\n",
    "```\n",
    "---\n",
    "\n",
    "## Transform\n",
    "\n",
    "### 4. `transform/translate_spanish_csv.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Finds any non-English survey columns, translates headers and responses to English, and writes a new CSV with only English columns.    \n",
    "> **Input:** Cleaned CSVs   \n",
    "> **Output:** Translated CSVs (English only, e.g., `processed/group_a/feedback_2021_en.csv`).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "df = pd.read_csv(\"processed/group_a/feedback_2021_spanish.csv\")\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str).apply(lambda x: translator.translate(x, src='es', dest='en').text)\n",
    "df.to_csv(\"processed/group_a/feedback_2021.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. `transform/audit_map.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Maps raw audit questions to canonical (standardized) question names using a mapping dictionary (e.g., `QCON_MAP`).\n",
    "> Cleans columns, drops junk, and saves a normalized audit file for each group.     \n",
    "> **Input:** Audit CSV  \n",
    "> **Output:** Canonicalized audit file (e.g., `audit_group_a_canonical.csv`).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "audit = pd.read_csv(\"audit_group_a.csv\")\n",
    "QCON_MAP = {\n",
    "    \"How safe do you feel?\": \"Feelings of Safety\",\n",
    "    \"Is there an adult you trust?\": \"Trusted Adult\",\n",
    "    # ... more sample mappings ...\n",
    "}\n",
    "audit[\"Canonical Question\"] = audit[\"Raw Question\"].map(QCON_MAP).fillna(audit[\"Raw Question\"])\n",
    "audit.to_csv(\"audit_group_a_canonical.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. `transform/summary_tables.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Generates summary tables (value counts, percentages, etc.) for every survey question/response, per group and year.    \n",
    "> **Input:** Processed/cleaned CSV      \n",
    "> **Output:** Summary CSVs (e.g., `processed/group_a/summary/group_a_2021_summary.csv`).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed/group_a/feedback_2021.csv\")\n",
    "summary = df.apply(pd.Series.value_counts).fillna(0).astype(int).T\n",
    "summary.to_csv(\"processed/group_a/summary/2021_GROUP_A_summary.csv\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. `transform/consolidate_responses.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Merges all per-question summary tables into a single master response table for each group.    \n",
    "> **Input:** All summary tables for a group     \n",
    "> **Output:** Master responses CSV (`processed/consolidated_responses_group_a.csv`).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "csvs = glob.glob(\"processed/group_a/summary/*.csv\")\n",
    "all_responses = pd.concat([pd.read_csv(f) for f in csvs], ignore_index=True)\n",
    "all_responses.to_csv(\"processed/consolidated_responses_group_a.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. `transform/consolidate_questions.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Aggregates consolidated responses by canonical question, response type, and year,\n",
    "> and appends a grouping column (\"Overarching\") for higher-level rollups.   \n",
    "> **Input:** Master responses CSV   \n",
    "> **Output:** Final consolidated questions file (`processed/consolidated_questions_group_a.csv`).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed/consolidated_responses_group_a.csv\")\n",
    "totals = df.groupby(\"Canonical Question\").sum(numeric_only=True).reset_index()\n",
    "totals.to_csv(\"processed/consolidated_questions_group_a.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 9. `transform/summarize_totals.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Merges and totals all canonical question files across groups and years,\n",
    "> creating a master totals table for high-level analysis.   \n",
    "> **Input:** All consolidated questions files   \n",
    "> **Output:** `processed/canonical_question_totals.csv`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_a = pd.read_csv(\"processed/consolidated_questions_group_a.csv\")\n",
    "df_b = pd.read_csv(\"processed/consolidated_questions_group_b.csv\")\n",
    "all_data = pd.concat([df_a, df_b], ignore_index=True)\n",
    "all_data = all_data.groupby(\"Canonical Question\").sum(numeric_only=True).reset_index()\n",
    "all_data.to_csv(\"processed/canonical_question_totals.csv\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Load\n",
    "\n",
    "### 10. `load/load_to_excel.py`\n",
    "\n",
    "> **Purpose:**\n",
    "> Combines all master summary and response files into a single Excel workbook,\n",
    "> with a \"Master Summary\" tab, group summary tabs, and per-year/group response tabs.    \n",
    "> **Input:** All summary/response CSVs      \n",
    "> **Output:** `processed/Master_Summary.xlsx` (anonymized name, all tabs generic, e.g., \"Group A Summary\", \"2021 Group A Responses\").\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "with pd.ExcelWriter(\"processed/Survey_Master_Summary.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    pd.read_csv(\"processed/canonical_question_totals.csv\").to_excel(writer, sheet_name=\"Master Summary\", index=False)\n",
    "    pd.read_csv(\"processed/consolidated_questions_group_a.csv\").to_excel(writer, sheet_name=\"Group A Summary\", index=False)\n",
    "    pd.read_csv(\"processed/consolidated_questions_group_b.csv\").to_excel(writer, sheet_name=\"Group B Summary\", index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Sample Survey Response Values for Testing (Example):**\n",
    "\n",
    "| Respondent | Satisfaction | Trust |\n",
    "| ---------- | ------------ | ----- |\n",
    "| 1          | Satisfied    | Yes   |\n",
    "| 2          | Unsatisfied  | No    |\n",
    "\n",
    "*All code, files, and responses here are anonymized and safe for open-source/public sharing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d53473",
   "metadata": {},
   "source": [
    "### ETL structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddee84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "scrape_drive_links.py\n",
    "   ↓\n",
    "load_feedback_data.py\n",
    "   ↓\n",
    "translate_spanish_csv.py\n",
    "   ↓\n",
    "raw_audit.py\n",
    "   ↓\n",
    "audit_map.py\n",
    "   ↓\n",
    "summary_tables.py\n",
    "   ↓\n",
    "consolidate_responses.py\n",
    "   ↓\n",
    "consolidate_questions.py\n",
    "   ↓\n",
    "summarize_totals.py\n",
    "   ↓\n",
    "load_to_excel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb13d2",
   "metadata": {},
   "source": [
    "## Bash Command to run the ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd73b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "#### `run_etl.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -euo pipefail\n",
    "# -e: Exit immediately if any command fails\n",
    "# -u: Treat unset variables as errors\n",
    "# -o pipefail: Fail if any command in a pipeline fails\n",
    "\n",
    "# Function to run a Python script and check for errors\n",
    "run_step() {\n",
    "    script_path=\"$1\"\n",
    "    step_desc=\"$2\"\n",
    "    if [[ ! -f \"$script_path\" ]]; then\n",
    "        echo \"❌ ERROR: Script not found: $script_path\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"=== $step_desc ===\"\n",
    "    if python \"$script_path\"; then\n",
    "        echo \"✅ SUCCESS: $step_desc\"\n",
    "    else\n",
    "        echo \"❌ ERROR: $step_desc failed.\"\n",
    "        exit 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Function to check that a required file exists before continuing\n",
    "check_exists() {\n",
    "    path=\"$1\"\n",
    "    desc=\"$2\"\n",
    "    if [[ ! -e \"$path\" ]]; then\n",
    "        echo \"❌ ERROR: Expected output not found: $desc ($path)\"\n",
    "        exit 1\n",
    "    fi\n",
    "    echo \"✅ Found: $desc ($path)\"\n",
    "}\n",
    "\n",
    "echo \"=== STARTING ETL PIPELINE ===\"\n",
    "\n",
    "# -------------------------------\n",
    "# EXTRACT STAGE\n",
    "# -------------------------------\n",
    "\n",
    "run_step \"scripts/extract/scrape_drive_links.py\" \"1. Scraping cloud drive links\"\n",
    "# Downloads all raw survey files (spreadsheets or CSVs) from cloud storage, and generates a mapping of available survey data.\n",
    "\n",
    "run_step \"scripts/extract/load_feedback_data.py\" \"2. Loading raw survey data\"\n",
    "# Loads and standardizes all survey files using the links mapping. Cleans headers, removes blanks, and organizes by group/year.\n",
    "\n",
    "run_step \"scripts/extract/translate_spanish_csv.py\" \"3. Translating non-English survey data\"\n",
    "# (If needed) Detects and translates survey files to English, producing new English-only CSVs.\n",
    "\n",
    "run_step \"scripts/extract/raw_audit.py\" \"4. Auditing survey question columns\"\n",
    "# Extracts all unique question columns for mapping and later canonicalization, outputs audit files for each group.\n",
    "\n",
    "# -- Extract output checks --\n",
    "check_exists \"data/raw/group_a_2021.csv\" \"Group A raw data (2021)\"\n",
    "check_exists \"data/raw/group_b_2021.csv\" \"Group B raw data (2021)\"\n",
    "check_exists \"audit_group_a.csv\" \"Group A question audit\"\n",
    "check_exists \"audit_group_b.csv\" \"Group B question audit\"\n",
    "\n",
    "# -------------------------------\n",
    "# TRANSFORM STAGE\n",
    "# -------------------------------\n",
    "\n",
    "run_step \"scripts/transform/audit_map.py\" \"5. Mapping audit questions to canonical names\"\n",
    "# Maps all question variants to a canonical list, cleans/join columns, and writes normalized audit files.\n",
    "\n",
    "run_step \"scripts/transform/summary_tables.py\" \"6. Generating summary tables\"\n",
    "# For each cleaned survey, generates response counts for every question, grouped by response type/scale.\n",
    "\n",
    "run_step \"scripts/transform/consolidate_responses.py\" \"7. Consolidating all response tables\"\n",
    "# Merges all per-question summary tables for each group into a single master response table for analysis.\n",
    "\n",
    "run_step \"scripts/transform/consolidate_questions.py\" \"8. Creating canonical question summaries\"\n",
    "# Aggregates response data by canonical question, year, and response type. Prepares for final reporting.\n",
    "\n",
    "run_step \"scripts/transform/summarize_totals.py\" \"9. Creating overall survey totals\"\n",
    "# Merges all group summaries into a unified master totals table for analysis and dashboarding.\n",
    "\n",
    "# -- Transform output checks --\n",
    "check_exists \"data/processed/consolidated_questions_group_a.csv\" \"Group A consolidated questions\"\n",
    "check_exists \"data/processed/consolidated_questions_group_b.csv\" \"Group B consolidated questions\"\n",
    "check_exists \"data/processed/canonical_question_totals.csv\" \"Canonical question totals\"\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD STAGE (EXPORT/REPORTING)\n",
    "# -------------------------------\n",
    "\n",
    "run_step \"scripts/load/load_to_excel.py\" \"10. Exporting all summaries to Excel\"\n",
    "# Combines all key summary and response files into a single Excel workbook, with clear tab naming for each group/year.\n",
    "\n",
    "echo \"=== PIPELINE COMPLETE ===\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary Table for Each Stage**\n",
    "\n",
    "| Stage     | What It Does                                             | Example Output                                 |\n",
    "| --------- | -------------------------------------------------------- | ---------------------------------------------- |\n",
    "| Extract   | Downloads and standardizes all survey data               | `data/raw/group_a_2021.csv`                    |\n",
    "| Transform | Maps, summarizes, and consolidates all questions/answers | `data/processed/canonical_question_totals.csv` |\n",
    "| Load      | Combines all results into Excel for reporting            | `processed/Master_Summary.xlsx`                |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
